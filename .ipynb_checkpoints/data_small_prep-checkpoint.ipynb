{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b106d267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "import sys\n",
    "import json\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f328d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv.field_size_limit(sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf778495",
   "metadata": {},
   "source": [
    "## Entities\n",
    "\n",
    "- user\n",
    "- artist\n",
    "- album\n",
    "- track\n",
    "- genre\n",
    "\n",
    "**Additional information:**\n",
    "- gender\n",
    "- country"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d666408d",
   "metadata": {},
   "source": [
    "#### Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "484fce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '05percent_subset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71808ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/lfm'\n",
    "path_prefix = 'data/lfm/intermediate_kg'\n",
    "read_path_prefix = 'data/lfm/%s' % name\n",
    "write_path_prefix = 'data/lfm/intermediate_kg/%s' % name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "172261e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/lfm/intermediate_kg/05percent_subset/05percent_subset_users.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# user_id, country, age, gender, creation_time\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_users.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m read_path_prefix, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m data, \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m_users.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwrite_path_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m     datareader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(data, quoting\u001b[38;5;241m=\u001b[39mcsv\u001b[38;5;241m.\u001b[39mQUOTE_NONE)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(datareader)):\n",
      "File \u001b[0;32m~/miniconda3/envs/pr/lib/python3.9/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/lfm/intermediate_kg/05percent_subset/05percent_subset_users.txt'"
     ]
    }
   ],
   "source": [
    "# user_id, country, age, gender, creation_time\n",
    "with open(\"%s_users.tsv\" % read_path_prefix, \"r\", encoding='utf-8') as data, open(\"%s_users.txt\" % write_path_prefix, \"w\") as f:\n",
    "    datareader = csv.reader(data, quoting=csv.QUOTE_NONE)\n",
    "    \n",
    "    for i, row in tqdm(enumerate(datareader)):\n",
    "        if i == 0:\n",
    "            header = row[0].split(sep=\"\\t\")\n",
    "        if i != 0:\n",
    "            entry = row[0].split(sep=\"\\t\")\n",
    "            f.writelines(\"u\" + entry[0] + \"\\t\" + entry[1] + \"\\t\" + entry[2] + \"\\t\" + entry[3] + \"\\n\")\n",
    "            \n",
    "time.sleep(0.5)            \n",
    "\n",
    "print(header)\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fc95f8",
   "metadata": {},
   "source": [
    "#### Artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b520ee6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# artist_id, artist_name\n",
    "#with open(\"data/artists.tsv\", \"r\", encoding='utf-8') as data, open(\"data/kg/artists.txt\", \"w\") as f:\n",
    "#    datareader = csv.reader(data, quoting=csv.QUOTE_NONE)\n",
    "#    \n",
    "#    for i, row in tqdm(enumerate(datareader)):\n",
    "#        if i == 0:\n",
    "#            header = row[0].split(sep=\"\\t\")\n",
    "#        if i != 0:\n",
    "#            entry = row[0].split(sep=\"\\t\")\n",
    "#            f.writelines(\"a\" + entry[0] + \"\\t\" + str(entry[1].encode(\"utf-8\")) + \"\\n\")\n",
    "#            \n",
    "#time.sleep(0.5)            \n",
    "#\n",
    "#print(header)\n",
    "#print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6073a06",
   "metadata": {},
   "source": [
    "#### Albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dc3b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# album_id, album_name, artist_name\n",
    "#with open(\"data/albums.tsv\", \"r\", encoding='utf-8') as data, open(\"data/kg/albums.txt\", \"w\") as f:\n",
    "#    datareader = csv.reader(data, quoting=csv.QUOTE_NONE)\n",
    "#    \n",
    "#    for i, row in tqdm(enumerate(datareader)):\n",
    "#        if i == 0:\n",
    "#            header = row[0].split(sep=\"\\t\")\n",
    "#        if i != 0:\n",
    "#            entry = row[0].split(sep=\"\\t\")\n",
    "#            f.writelines(\"b\" + entry[0] + \"\\t\" + str(entry[1].encode(\"utf-8\")) +  \"\\n\")\n",
    "#            \n",
    "#time.sleep(0.5)\n",
    "#\n",
    "#print(header)\n",
    "#print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3c7f06",
   "metadata": {},
   "source": [
    "#### Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064536b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# track_id, artist_name, track_name\n",
    "track_complete_dict = {}\n",
    "counter = 0\n",
    "with open(\"%s_tracks.tsv\" % read_path_prefix, \"r\", encoding='utf-8') as data, open(\"%s_tracks.txt\" % write_path_prefix, \"w\") as f:\n",
    "    datareader = csv.reader(data, quoting=csv.QUOTE_NONE)\n",
    "    \n",
    "    for i, row in tqdm(enumerate(datareader)):\n",
    "        if i == 0:\n",
    "            header = row[0].split(sep=\"\\t\")\n",
    "        if i != 0:\n",
    "            entry = row[0].split(sep=\"\\t\")\n",
    "            try:\n",
    "                f.writelines(\"t\" + entry[0] + \"\\t\" + str(entry[2].encode(\"utf-8\")) + \"\\n\")\n",
    "                track_id = \"t\" + entry[0]\n",
    "                if track_id not in track_complete_dict:\n",
    "                    track_complete_dict[track_id] = 0\n",
    "            except:\n",
    "                f.writelines(\"t\" + entry[0] + \"\\t\" + \"???\" + \"\\n\")\n",
    "                counter += 1\n",
    "            \n",
    "time.sleep(0.5)            \n",
    "\n",
    "print(header)\n",
    "print(\"done.\")\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e837b10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list(track_complete_dict.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450aef85",
   "metadata": {},
   "source": [
    "#### Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577ff52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#counter = 0\n",
    "#with open(\"data/micro_genre_tags.json\", \"r\", encoding='utf-8') as data, open(\"data/kg/genres.txt\", \"w\") as f:\n",
    "#    for line in tqdm(data):\n",
    "#        try:\n",
    "#            entry = json.loads(line)\n",
    "#            track_name = entry['_id']['track']\n",
    "#            artist_name = entry['_id']['artist']\n",
    "#            main_genre = list(entry['tags'].keys())[0]\n",
    "#            genres = \",\".join(list(entry['tags'].keys()))\n",
    "#\n",
    "#            f.writelines(track_name + \"\\t\" + artist_name + \"\\t\" + main_genre + \"\\t\" + genres + \"\\n\")\n",
    "#        except:\n",
    "#            counter += 1\n",
    "#            continue\n",
    "#            \n",
    "#time.sleep(0.5)            \n",
    "#\n",
    "#print(header)\n",
    "#print(\"done.\")\n",
    "#print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4aafb6",
   "metadata": {},
   "source": [
    "#### Gender & Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561ce758",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdict = {}\n",
    "cdict = {}\n",
    "\n",
    "gcounter = 0\n",
    "ccounter = 0\n",
    "\n",
    "with open(\"%s_users.txt\" % write_path_prefix, \"r\") as data,\\\n",
    "open(\"%s/entities/%s_gender.txt\"  % (path_prefix, name), \"w\") as f,\\\n",
    "open(\"%s/entities/%s_country.txt\" % (path_prefix, name), \"w\") as f2:\n",
    "    datareader = csv.reader(data)\n",
    "    \n",
    "    for i, row in tqdm(enumerate(datareader)):\n",
    "        entry = row[0].split(sep=\"\\t\")\n",
    "        if entry[3] == \"\" or entry[3] in gdict:\n",
    "            gcounter += 1\n",
    "        else:\n",
    "            gdict[entry[3]] = 0\n",
    "            f.writelines(entry[3] + \"\\n\")\n",
    "            \n",
    "        if entry[1] == \"\" or entry[1] in cdict:\n",
    "            ccounter += 1\n",
    "        else:\n",
    "            cdict[entry[1]] = 0\n",
    "            f2.writelines(entry[1] + \"\\n\")\n",
    "            \n",
    "time.sleep(0.5)\n",
    "            \n",
    "print(\"done.\")\n",
    "print(gcounter)\n",
    "print(ccounter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24ca723",
   "metadata": {},
   "source": [
    "#### Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03788db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ff0f92",
   "metadata": {},
   "source": [
    "## Relations\n",
    "\n",
    "- **listened_to:** _user_ listened_to _track_\n",
    "- **in_album:** _track_ in_album _album_\n",
    "- **created_by:** _track_ created_by _artist_\n",
    "- **has_genre**: _track_ has_genre _genre_\n",
    "\n",
    "**Additional information:**\n",
    "- **has_micro_genre**: _track_ has_micro_genre _genre_ (**or** instead of has_genre)\n",
    "- **has_gender**: _user_ has_gender _gender_\n",
    "- **lives_in**: _user_ lives_in _country_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabbb76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check genres.txt --> clean track and artist names, we filter it with that list?\n",
    "# create new dict mit track names, artist names and look up for all the relations\n",
    "\n",
    "# track_name, artist_name, main_genre, micro_genre\n",
    "\n",
    "#track_dict = {}\n",
    "\n",
    "#with open(\"data/kg/genres.txt\", \"r\") as data: #, open(\"data/kg/tracks.txt\", \"w\") as f:\n",
    "#    datareader = csv.reader(data)\n",
    "    \n",
    "#    for i, row in tqdm(enumerate(datareader)):\n",
    "#        try:\n",
    "#            helper = row[0].split(\"\\t\")\n",
    "#            track_name = helper[0]\n",
    "#            artist_name = helper[1]\n",
    "#            main_genre = helper[2]\n",
    "#            micro_genre = row[1:]\n",
    "#        except:\n",
    "#            row = \", \".join(row)\n",
    "#            helper = row.split(\"\\t\")\n",
    "            \n",
    "#            track_name = helper[0]\n",
    "#            artist_name = helper[1]\n",
    "#            main_genre = helper[2]\n",
    "#            micro_genre = helper[3].split(\",\")[1:]\n",
    "#            continue\n",
    "        \n",
    "#        key = track_name # + \" || \" + artist_name\n",
    "        \n",
    "#        if key not in track_dict:\n",
    "#            track_dict[key] = {}\n",
    "#            track_dict[key][\"artist\"] = artist_name\n",
    "#            track_dict[key][\"main_genre\"] = main_genre\n",
    "#            track_dict[key][\"micro_genre\"] = micro_genre\n",
    "        \n",
    "#print(\"saving...\")\n",
    "\n",
    "#joblib.dump(track_dict, \"data/kg/track_dict.pkl\")\n",
    "\n",
    "#print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae66d7d8",
   "metadata": {},
   "source": [
    "#### listened_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2117b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_id, track_id, album_id, timestamp\n",
    "counter = 0\n",
    "counts_dict = {}\n",
    "track_dict = {}\n",
    "with open(\"%s_listening_events.tsv\" % (read_path_prefix), \"r\") as data, open(\"%s/relations/%s_listened_to.txt\" % (path_prefix, name), \"w\") as f:\n",
    "    datareader = csv.reader(data)\n",
    "    \n",
    "    for i, row in tqdm(enumerate(datareader)):\n",
    "        if i == 0:\n",
    "            header = row[0].split(sep=\"\\t\")\n",
    "        if i != 0:\n",
    "            entry = row[0].split(sep=\"\\t\")\n",
    "            \n",
    "            track_id = \"t\" + entry[1]\n",
    "            if track_id not in track_dict:\n",
    "                track_dict[track_id] = 0\n",
    "            \n",
    "            key = \"u\" + entry[0] + \", \" + \"listened_to\" + \", \" + \"t\" + entry[1]\n",
    "            if key not in counts_dict:\n",
    "                counts_dict[key] = 0\n",
    "                f.writelines(\"u\" + entry[0] + \"\\t\" + \"listened_to\" + \"\\t\" + \"t\" + entry[1] + \"\\n\")\n",
    "            else:\n",
    "                counts_dict[key] += 1\n",
    "                \n",
    "            #try:\n",
    "            #    f.writelines(\"u\" + entry[0] + \"\\t\" + \"listened_to\" + \"\\t\" + \"t\" + entry[1] + \"\\n\")\n",
    "            #except:\n",
    "            #    counter += 1\n",
    "            #    continue\n",
    "            \n",
    "time.sleep(0.5)            \n",
    "\n",
    "print(header)\n",
    "print(\"done.\")\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a799c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list(track_dict.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf88147",
   "metadata": {},
   "source": [
    "#### created_by & has_genre & has_micro_genre & in_album"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f34bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "artist_dict = {}\n",
    "album_dict = {}\n",
    "type_dict = {}\n",
    "genre_dict = {}\n",
    "check_dict = {}\n",
    "\n",
    "with open(\"%s/micro_genre_tags_new.json\" % path, \"r\", encoding='utf-8') as data,\\\n",
    "open(\"%s/relations/%s_has_genre.txt\" % (path_prefix, name), \"w\", encoding='utf-8') as f1,\\\n",
    "open(\"%s/relations/%s_has_micro_genre.txt\" % (path_prefix, name), \"w\", encoding='utf-8') as f2,\\\n",
    "open(\"%s/relations/%s_in_album.txt\" % (path_prefix, name), \"w\", encoding='utf-8') as f3,\\\n",
    "open(\"%s/relations/%s_created_by.txt\" % (path_prefix, name), \"w\", encoding='utf-8') as f4,\\\n",
    "open(\"%s/entities/%s_artist.txt\" % (path_prefix, name), \"w\", encoding='utf-8') as e1,\\\n",
    "open(\"%s/entities/%s_album.txt\" % (path_prefix, name), \"w\", encoding='utf-8') as e2,\\\n",
    "open(\"%s/entities/%s_artist_type.txt\" % (path_prefix, name), \"w\", encoding='utf-8') as e3,\\\n",
    "open(\"%s/entities/%s_genre.txt\" % (path_prefix, name), \"w\", encoding='utf-8') as e4,\\\n",
    "open(\"%s/entities/%s_track.txt\" % (path_prefix, name), \"w\", encoding='utf-8') as t: #?????????\n",
    "    for line in tqdm(data):\n",
    "        entry = json.loads(line)\n",
    "        #print(entry)\n",
    "        track_id = str(entry['_id'])\n",
    "        track_name = str(entry['track']['track']) #?????????\n",
    "        main_genre = str(list(entry['tags'].keys())[0])\n",
    "        micro_genre = list(entry['tags'].keys())[1:]\n",
    "        \n",
    "        artist_id = str(entry['artist']['artist_id'])\n",
    "        artist_name = str(entry['artist']['artist'])\n",
    "        artist_gender = str(entry['artist']['gender'])\n",
    "        artist_type = str(entry['artist']['type'])\n",
    "        \n",
    "        album_id = str(entry['album']['album_id'])\n",
    "        album_name = str(entry['album']['album'])\n",
    "        \n",
    "        check = \"t\" + track_id\n",
    "        if check in track_dict:\n",
    "            if check not in check_dict: #?????????\n",
    "                check_dict[check] = 0\n",
    "                track_dict[check] = track_name\n",
    "                t.writelines(check + \"\\t\" + track_name + \"\\n\")\n",
    "                \n",
    "            if artist_id not in artist_dict:\n",
    "                artist_dict[artist_id] = 0\n",
    "                e1.writelines(\"a\" + artist_id + \"\\t\" + artist_name + \"\\t\" + artist_gender + \"\\t\" + artist_type + \"\\n\")\n",
    "\n",
    "            if album_id not in album_dict:\n",
    "                album_dict[album_id] = 0\n",
    "                e2.writelines(\"b\" + album_id + \"\\t\" + album_name + \"\\n\")\n",
    "\n",
    "            if artist_type not in type_dict:\n",
    "                type_dict[artist_type] = 0\n",
    "                e3.writelines(artist_type + \"\\n\")\n",
    "\n",
    "            if main_genre not in genre_dict:\n",
    "                genre_dict[main_genre] = 0\n",
    "                e4.writelines(main_genre + \"\\n\")\n",
    "\n",
    "            for micro in micro_genre:\n",
    "                m = str(micro)\n",
    "                if m not in genre_dict:\n",
    "                    genre_dict[m] = 0\n",
    "                    e4.writelines(m + \"\\n\")\n",
    "\n",
    "            created_by = \"t\" + track_id + \"\\t\" + \"created_by\" + \"\\t\" + \"a\" + artist_id + \"\\n\"\n",
    "            f4.writelines(created_by)\n",
    "            #print(created_by)\n",
    "            has_genre = \"t\" + track_id + \"\\t\" + \"has_genre\" + \"\\t\" + main_genre + \"\\n\"\n",
    "            f1.writelines(has_genre)\n",
    "            #print(has_genre)\n",
    "            for micro in micro_genre:\n",
    "                has_micro_genre = \"t\" + track_id + \"\\t\" + \"has_micro_genre\" + \"\\t\" + micro + \"\\n\"\n",
    "                f2.writelines(has_micro_genre)\n",
    "            #    print(has_micro_genre)\n",
    "            in_album = \"t\" + track_id + \"\\t\" + \"in_album\" + \"\\t\" + \"b\" + album_id + \"\\n\"\n",
    "            f3.writelines(in_album)\n",
    "            #print(in_album)\n",
    "        else:\n",
    "            counter += 1\n",
    "            \n",
    "time.sleep(0.5)            \n",
    "\n",
    "print(\"done.\")\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5ae357",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list(check_dict.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dca77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"%s/entities/%s_track_new.txt\" % (path_prefix, name), \"w\", encoding='utf-8') as t:\n",
    "    for key, value in tqdm(track_dict.items()):\n",
    "        track_id = key\n",
    "        track_name = value\n",
    "        \n",
    "        if track_name == 0:\n",
    "            track_name = \"???\"\n",
    "            \n",
    "        t.writelines(track_id + \"\\t\" + track_name + \"\\n\")\n",
    "        \n",
    "time.sleep(0.5)\n",
    "        \n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0797f2",
   "metadata": {},
   "source": [
    "#### in_album"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbc58a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55de12ca",
   "metadata": {},
   "source": [
    "#### has_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c552ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d66a2e",
   "metadata": {},
   "source": [
    "#### has_micro_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d39acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bcc2b3",
   "metadata": {},
   "source": [
    "#### has_gender & lives_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ac31b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_id, country, age, gender, creation_time\n",
    "gcounter = 0\n",
    "ccounter = 0\n",
    "with open(\"%s_users.txt\" % write_path_prefix, \"r\") as data,\\\n",
    "open(\"%s/relations/%s_has_gender.txt\" % (path_prefix, name), \"w\") as f,\\\n",
    "open(\"%s/relations/%slives_in.txt\" % (path_prefix, name), \"w\") as f2:\n",
    "    datareader = csv.reader(data)\n",
    "    \n",
    "    for i, row in tqdm(enumerate(datareader)):\n",
    "        entry = row[0].split(sep=\"\\t\")\n",
    "        if entry[3] == \"\":\n",
    "            gcounter += 1\n",
    "        else:\n",
    "            f.writelines(entry[0] + \"\\t\" + \"has_gender\" + \"\\t\" + entry[3] + \"\\n\")\n",
    "            \n",
    "        if entry[1] == \"\":\n",
    "            ccounter += 1\n",
    "        else:\n",
    "            f2.writelines(entry[0] + \"\\t\" + \"lives_in\" + \"\\t\" + entry[1] + \"\\n\")\n",
    "            \n",
    "time.sleep(0.5)\n",
    "print(\"done.\")\n",
    "print(gcounter)\n",
    "print(ccounter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7835701a",
   "metadata": {},
   "source": [
    "#### lives_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f0a14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a22fd1",
   "metadata": {},
   "source": [
    "# Create KG File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2737b548",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '%s/relations' % path_prefix\n",
    " \n",
    "with open('%s_kg.txt' % write_path_prefix, \"w\") as kg:\n",
    "    for filename in os.listdir(directory):\n",
    "        f = os.path.join(directory, filename)\n",
    "        with open(f, \"r\") as rel:\n",
    "            datareader = csv.reader(rel)\n",
    "            for i, row in tqdm(enumerate(datareader), desc=filename):\n",
    "                kg.writelines(row[0] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae843b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '%s/relations' % path_prefix\n",
    " \n",
    "with open('%s_kg_no_gender.txt' % write_path_prefix, \"w\") as kg:\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename == 'has_gender.txt':\n",
    "            continue\n",
    "        f = os.path.join(directory, filename)\n",
    "        with open(f, \"r\") as rel:\n",
    "            datareader = csv.reader(rel)\n",
    "            for i, row in tqdm(enumerate(datareader), desc=filename):\n",
    "                kg.writelines(row[0] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de1e158",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
